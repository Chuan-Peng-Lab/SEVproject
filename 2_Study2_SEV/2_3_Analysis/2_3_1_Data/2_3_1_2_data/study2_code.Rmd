---
title: "SEV_formal_study_code Notebook"
output: html_notebook
---

# install packages
```{r install packages}
library(psych)
library(tidyverse)
library(showtext)
library(ggforce)
library(gghalves)
library(cowplot)
library(broom)
library(multcomp)
library(nlme)
library(boot)
```

# import data
```{r import data}
raw_data1<-read.csv("./SEV01_original.csv",header = T,encoding="UTF-8")
raw_data2<-read.csv("./SEV02_original.csv",header = T,encoding="UTF-8")
```

# View and convert data types
```{r View and convert data types,warning=FALSE}
con_data <- function(data) {
  vars1 <- c("Sex", "Education")
  vars2 <- c("BirthYear", "wordLen", "rating", "validity", "rt")
  
  data[vars1] <- lapply(data[vars1], factor)
  data[vars2] <- lapply(data[vars2], as.numeric)
  
  data <- data %>% 
    select(-c(response, trial_index, time_elapsed, internal_node_id)) %>%
    mutate(isTrap = as.logical(isTrap))
  
  return(data)
}

raw_data1 <- con_data(raw_data1)
raw_data2 <- con_data(raw_data2)
```

# Trap selection
see "Data cleaning" of the article for details
```{r 13 attention questions}
## 13 attention questions
### 1.extract
trap_1 <- raw_data1 %>%
  dplyr::filter(
    isTrap == TRUE
  )

### 2.judge
trap_2 <- trap_1 %>%
  dplyr::mutate(
    trap_right = ifelse(
      !is.na(rating),
      rating == wordGroup,
      validity == wordGroup
    )
  ) %>%
  dplyr::nest_by(
    subj_idx, Birthplace
  ) %>%
  dplyr::mutate(
    n = length(data$trap_right[data$trap_right == TRUE])
  ) %>%
  dplyr::filter(
    n == 13
  )
trap_3 <- unique(trap_2$subj_idx)

raw_data1<-raw_data1 %>% dplyr::filter(subj_idx %in% trap_3)
raw_data1_manual<-c('SEVNC1672','SEVNC1674','SEVNC1685','SEVNC1661','SEVNC491','SEVCC1959','SEVCC1956','SEVCC2002','SEVSW1774','SEVSW1790','SEVSW1787','SEVSW1818','SEVSW1771','SEVSW1880','SEVSW1908','SEVSW1986','SEVSW1987','SEVEC1631','SEVNW1856','SEVNW1867','SEVNW638','SEVNW669','SEVNW696','SEVNW699','SEVNW2006','SEVNW1977','SEVNW1978','SEVNW1979','SEVNW2026','SEVNW662','SEVNW1980','SEVNW2008','SEVNW2022')
raw_data1_final<- raw_data1 %>% dplyr::filter(!(subj_idx %in% raw_data1_manual)) %>% dplyr::select(-serial)
```

```{r 3 attention questions}
## 3 attention questions
clean1<-raw_data2 %>% dplyr::filter((isTrap==TRUE & rating!=1)|(isTrap==TRUE & validity!=6))
clean2<-raw_data2 %>% dplyr::filter(blockNum==20 & isTrap!=TRUE) %>% group_by(subj_idx) %>% summarise(sds=sd(rating))
clean3<-raw_data2 %>% dplyr::filter(blockNum==24 & isTrap!=TRUE) %>% group_by(subj_idx) %>% summarise(sds=sd(validity))

raw_data2_auto<-clean1$subj_idx
raw_data2_manual<-c('SEVCC761','SEVCC862','SEVCC763','SEVCC772','SEVCC815','SEVCC817','SEVCC824','SEVCC899','SEVCC1352','SEVCC1355','SEVCC1356','SEVCC1357','SEVCC1427','SEVCC844','SEVCC1360','SEVCC1470','SEVCC1471','SEVCC1473','SEVCC1474','SEVCC1475','SEVCC1477','SEVCC1479','SEVCC1481','SEVEC075','SEVEC1273','SEVNC394','SEVNC503','SEVNC460','SEVNC518','SEVNC465','SEVNC1401','SEVNC428','SEVNC487','SEVNE225','SEVNE251','SEVNE359','SEVNE338','SEVNE333','SEVNE334','SEVNE1502','SEVNE1507','SEVNE1520','SEVNE344','SEVNE1509','SEVNE1510','SEVNE1503','SEVNE345','SEVNE1572','SEVNE1568','SEVNE308','SEVNW597','SEVNW587','SEVNW588','SEVNW621','SEVNW711','SEVNW718','SEVNW578','SEVNW583','SEVNW601','SEVNW602','SEVNW585','SEVSC1054','SEVSC1318','SEVSC922','SEVSC1040','SEVSC935','SEVSC1496','SEVSC975','SEVSC1602','SEVSC971','SEVSC970','SEVSC1611','SEVSC1331','SEVSC1329','SEVSW1087','SEVSW1088','SEVSW1092','SEVSW1112','SEVSW1195','SEVSW1222')
raw_data2_final<- raw_data2 %>% dplyr::filter(!(subj_idx %in% c(raw_data2_auto,raw_data2_manual)))
```

# Total data after cleaning
```{r Total data after cleaning}
process_data<-rbind(raw_data1_final,raw_data2_final)
process_data <- process_data %>% mutate(word = trimws(word))  #remove leading and trailing whitespace from a string
```

# Information of participants
```{r Information of participants}
sub<- process_data %>% dplyr::mutate(age=2023-BirthYear) %>%
  dplyr::distinct(subj_idx, Sex, age,Education) 

sub_total<-sub %>% dplyr::summarise(subj_N = length(subj_idx), 
                   female_N = sum(Sex == 'Female'),
                   male_N = sum(Sex == 'Male'),
                   Age_mean = round(mean(age),2), 
                   Age_sd   = round(sd(age),2),range(age))

regions <- c("CC", "EC", "NW", "SC", "NC", "NE", "SW")
summary_data <- data.frame(region = character(), subj_N = numeric(), female_N = numeric(), male_N = numeric(), Age_mean = numeric(), Age_sd = numeric(), age_range = character(), stringsAsFactors = FALSE)

for (region in regions) {
  data_filter <- grep(paste0("^SEV", region), sub$subj_idx)
  data_region <- sub[data_filter, ]
  
  summary <- data_region %>%
    dplyr::summarise(
      subj_N = length(subj_idx),
      female_N = sum(Sex == 'Female'),
      male_N = sum(Sex == 'Male'),
      Age_mean = round(mean(age), 2),
      Age_sd = round(sd(age), 2),
      age_range = paste(range(age), collapse = " - ")
    )
  
  summary$region <- region
  summary_data <- rbind(summary_data, summary)
  }

sub.region<- summary_data[, c("region", "subj_N", "female_N", "male_N", "Age_mean", "Age_sd", "age_range")]
```

# reliability cauclation
```{r word rating reliability}
split_half_reliability <- function(data) {
    data <- data[, -(1)]
    part1 <- data[, seq(1, ncol(data), 2)]
    part2 <- data[, seq(2, ncol(data), 2)]

    total1 <- rowMeans(part1, na.rm = TRUE)
    total2 <- rowMeans(part2, na.rm = TRUE)

    r <- cor(total1, total2,method = "spearman")
    r_spearman_brown <- (2 * r) / (1 + r)
    return(r_spearman_brown)
}

getSplitAndICC <- function(dd) {
    v       <- ICC(dd[,-1],lmer=FALSE)
    s.aov   <- v$summary
    stats   <- matrix(unlist(s.aov),ncol=3,byrow=TRUE)
    MSR     <- stats[3,1]
    MSW     <- (stats[2,2]+stats[2,3])/(stats[1,2]+stats[1,3])
    MSC     <- stats[3,2]
    MSE     <- stats[3,3]
    n.obs   <- dim(dd)[1]

    split_r <- split_half_reliability(dd)
    ICC22   <- (MSR- MSE)/(MSR +(MSC-MSE)/n.obs)
    return(data.frame(split = split_r, ICC22 = ICC22))
}

record_dimension <- c() # dimension
record_type      <- c() # word set
record_r_type    <- c() # reliability type
record_r_value   <- c() # reliability value
for (v_type in sort(unique(process_data$Type))) {
   for (v_dimension in unique(process_data$dimension)[c(1:5)]) {
        # dimension
        dd <- process_data %>%
            dplyr::filter(
                !is.na(rating),
                isTrap == FALSE,
                Type == v_type,
                dimension == v_dimension
            ) %>%
            dplyr::select(
                subj_idx, word, rating
            ) %>%
            pivot_wider(
                names_from = subj_idx,
                values_from = rating
            )
        
        dd.r <- getSplitAndICC(dd)
        for (col in colnames(dd.r)) {
            record_dimension <- c(record_dimension, v_dimension)
            record_type <- c(record_type, v_type)
            record_r_type <- c(record_r_type, col)
            record_r_value <- c(record_r_value, dd.r[, col])
        }
   }
    # val
    dd_val <- process_data %>%
        dplyr::filter(
            !is.na(validity),
            isTrap == FALSE,
            Type == v_type,
        ) %>%
        dplyr::select(
            subj_idx, word, validity
        ) %>%
        pivot_wider(
            names_from = subj_idx,
            values_from = validity
        )
    
    dd_val.r <- getSplitAndICC(dd_val)
    for (col in colnames(dd_val.r)) {
        record_dimension <- c(record_dimension, "val")
        record_type <- c(record_type, v_type)
        record_r_type <- c(record_r_type, col)
        record_r_value <- c(record_r_value, dd_val.r[, col])
    }
    print(v_type)
}

df_r <- data.frame(
    record_dimension = record_dimension,
    record_type = record_type,
    record_r_type = record_r_type,
    record_r_value = record_r_value
) %>% pivot_wider(
    names_from = record_type,
    values_from = record_r_value
)
df_r$mean_r = rowMeans(df_r[, c(3:7)])
```

# Words dimension classification
see Fig.4 of the article for details

## 1.average rating
```{r average rating,message=FALSE}
ave <-process_data %>% dplyr::filter(isTrap == FALSE) %>%
  dplyr::nest_by(word, dimensionEn) %>%
  dplyr::mutate(
    mean = ifelse(dimensionEn == "",
                 round(mean(data$validity), 3),
                 round(mean(data$rating), 3)),
    sd = ifelse(dimensionEn == "",
                round(sd(data$validity), 3),
                round(sd(data$rating), 3)),
    dimensionEn = ifelse(dimensionEn == "", "val", dimensionEn)
  ) %>%
  dplyr::select(
    -c("data")
  ) 

word_score_average<- ave %>%
  pivot_wider(
    names_from = "dimensionEn",
    values_from = c("mean", "sd"),
    names_glue = "{dimensionEn}_{.value}"
  ) 
new_order<-c("word","appearance_mean","appearance_sd","socioEconomicStatus_mean","socioEconomicStatus_sd","socialAbility_mean","socialAbility_sd","ability_mean","ability_sd","morality_mean","morality_sd","val_mean","val_sd")
word_score_average<-word_score_average %>% select(new_order) %>% as.data.frame()

dimension_columns<-c("appearance_mean","socioEconomicStatus_mean","socialAbility_mean","ability_mean","morality_mean")
filtered_words_average <- word_score_average %>%
  rowwise() %>%
  filter(all(c_across(all_of(dimension_columns)) <= 5))

filtered_words_list <- filtered_words_average$word
filtered_words_sev <- ave %>%
  filter(!(word %in% filtered_words_list))
```

## 2.statistical tests
```{r statistical tests}
aov_data_ori<-process_data %>% dplyr::filter(
  is.na(validity),
  isTrap == F, word %in% filtered_words_sev$word
) %>% dplyr::select(
  subj_idx, word, dimensionEn, rating
) 
aov_data_ori$dimensionEn <- as.factor(aov_data_ori$dimensionEn)

result_list <- list()
words <- unique(aov_data_ori$word)
for (word in words) {
  subset_df <- aov_data_ori %>% filter(word == !!word)
  lme_model <- lme(rating ~ dimensionEn, random = ~ 1 | subj_idx, data = subset_df)
  
  anova_result <- anova(lme_model)
    if (anova_result['dimensionEn','p-value'] < 0.05) {
        # Significant effect: conduct post-hoc test
        tukey_test <- glht(lme_model, linfct = mcp(dimensionEn = "Tukey"))
        summary_tukey <- summary(tukey_test)
        
        tukey_df <- cbind(
            Word = word,
            Comparison = rownames(summary_tukey$test$coefficients),
            Estimate = summary_tukey$test$coefficients,
            p_value = summary_tukey$test$pvalues
        )
        result_list[[length(result_list) + 1]] <- tukey_df
    } else {
        # No significant effect: record basic info
        no_effect_df <- data.frame(
            Word = word,
            Comparison = NA,
            Estimate = NA,
            p_value = NA
        )
        result_list[[length(result_list) + 1]] <- no_effect_df
    }
}
  
 final_results <- do.call(rbind, result_list)
 final_results <- data.frame(
    Dimension = rownames(final_results),  
    final_results
)
 write.csv(final_results, "t_test_results.csv", row.names = FALSE)
```

## 3.Count-based
```{r Count-based}
###aov_wordlist: word list compiled from Step 2 results
aov_wordlist <- read.csv("./aov_wordlist.csv",header = T,encoding="UTF-8")  

### all participants' ratings in 1134 words
aov_wordlist_filter <- aov_wordlist %>% filter(dimension_fin != "ambiguity")
process_data_filter <- process_data %>% dplyr::filter(
  word %in% unique(aov_wordlist_filter$word),
  dimensionEn != "")

### Number of raters per word
word_sub_num <- process_data_filter %>% dplyr::group_by(word) %>% 
  dplyr::summarise(
  n = n() / 5)

### Number of subjects choosing words under each dimensions
tmp1 <- process_data_filter %>% dplyr::nest_by(
  subj_idx, word
) %>% dplyr::mutate(
  belong_n = list(data$dimensionEn[data$rating == max(data$rating)]),
  actual_num = length(data$dimensionEn[data$rating == max(data$rating)]),
  belong_to = sample(data$dimensionEn[data$rating == max(data$rating)], size = 1),
  isLow = ifelse(max(data$rating) <= 5, 1, 0),
  isArray = ifelse(actual_num == 1, 0, 1)
) %>% dplyr::select(-data)

tmp2 <- tmp1 %>% dplyr::nest_by(
  word, belong_to
) %>% dplyr::mutate(
  effective_useful = length(data$subj_idx[data$isLow == 0 & data$isArray == 0]),
  invalid = length(data$subj_idx[data$isLow == 1 & data$isArray == 0]) + length(data$subj_idx[data$isLow == 1 & data$isArray == 1]),
  effective_useless = length(data$subj_idx[data$isLow == 0 & data$isArray == 1])
) %>% dplyr::select(-data)
```

### Calculate percentage
```{r Calculate percentage}
#### valid number
tmp3 <- tmp1 %>% dplyr::nest_by(
  word, belong_to
) %>% dplyr::select(-data) %>% dplyr::mutate(
  effective_degree = tmp2$effective_useful[
    tmp2$word == word & tmp2$belong_to == belong_to
  ] / sum(
    tmp2$effective_useful[
      tmp2$word == word
    ],
    tmp2$invalid[
      tmp2$word == word
    ],
    tmp2$effective_useless[
      tmp2$word == word
    ]
  ),
  max_dimension = tmp2$belong_to[
    tmp2$word == word & tmp2$effective_useful == max(
      tmp2$effective_useful[tmp2$word == word]
    )
  ][1])

#### invalid number
tmp3_low <- data.frame()
tmp3_amb <- data.frame()
for (i in unique(tmp3$word)) {
  tmp3_low <- rbind(tmp3_low, data.frame(
    word = c(i),
    belong_to = c("none"),
    effective_degree = c(
      sum(
        tmp2$invalid[
          tmp2$word == i
        ]
      ) / sum(
        tmp2$effective_useful[
          tmp2$word == i
        ],
        tmp2$invalid[
          tmp2$word == i
        ],
        tmp2$effective_useless[
          tmp2$word == i
        ]
      )
    ),
    max_dimension = tmp2$belong_to[
      tmp2$word == i & tmp2$effective_useful == max(
        tmp2$effective_useful[tmp2$word == i]
      )
    ][1]
  ))
  
  tmp3_amb <- rbind(tmp3_amb, data.frame(
    word = c(i),
    belong_to = c("ambiguity"),
    effective_degree = c(
      sum(
        tmp2$effective_useless[
          tmp2$word == i
        ]
      ) / sum(
        tmp2$effective_useful[
          tmp2$word == i
        ],
        tmp2$invalid[
          tmp2$word == i
        ],
        tmp2$effective_useless[
          tmp2$word == i
        ]
      )
    ),
    max_dimension = tmp2$belong_to[
      tmp2$word == i & tmp2$effective_useful == max(
        tmp2$effective_useful[tmp2$word == i]
      )
    ][1]
  ))
}
tmp3 <- rbind(tmp3, tmp3_amb, tmp3_low)
rm(tmp3_amb, tmp3_low, i)
```

### Bar chart
corresponds to Fig.5 in the article
```{r Bar chart,warning=FALSE}
#### 1.rank
for (i in seq(1, length(tmp3$word), 1)) {
  max_indices <- which(tmp3$word == tmp3$word[i] & tmp3$effective_degree == max(tmp3$effective_degree[tmp3$word == tmp3$word[i]]))

if (length(max_indices) > 1) {
    tmp3$max_dimension[i] <- "ambiguity"
  } else {
    tmp3$max_dimension[i] <- tmp3$belong_to[max_indices]
  }
}

tmp4 <- tmp3 %>% dplyr::nest_by(
  word
) %>% dplyr::mutate(
  max_dimension = unique(data$max_dimension),
  max_values = max(data$effective_degree)
) %>% dplyr::select(-data) %>% dplyr::arrange(
  max_dimension, max_values
)

tmp3$word <- factor(tmp3$word, unique(tmp4$word))
tmp3$belong_to <- factor(tmp3$belong_to, levels = c(
  "appearance", "socioEconomicStatus","socialAbility","ability", "morality", 
  "none","ambiguity"
))

#### 2.draw
showtext_auto()
belong_to_name <- c(
  `appearance` = "Appearance",
  `socioEconomicStatus` = "Socioeconomic status",
  `socialAbility` = "Sociability",
  `ability` = "Competence",
  `morality` = "Morality",
  `none` = "Non-five",
  `ambiguity` = "Ambiguous"
)

tmp3 <- ungroup(tmp3) %>%
  dplyr::filter(max_dimension %in% c("appearance", "socioEconomicStatus", "socialAbility", "ability", "morality"))

tmp3$max_dimension <- factor(
  tmp3$max_dimension,
  levels = c("appearance", "socioEconomicStatus","socialAbility","ability", "morality","none","ambiguity"),
  labels = belong_to_name)

ggplot(data = tmp3, aes(x = word, y = effective_degree, fill = belong_to)) +
  geom_bar(position = "stack", stat = "identity", width = 0.6) +
  scale_fill_manual(
  values=rev(c("#FF00AA","#00FF00","#3333ff",
              "#FF00FF","#FFFF00","#0099e6","#ff4d4d")),
  labels=c("Appearance","Socioeconomic status","Sociability","Competence","Morality","Non-five","Ambiguous"),
  name = "Dimension") +
  labs(x="Words",y="Percentage") +
  theme(
    axis.text.x=element_text(angle = 90, colour = "black", hjust=1,size = 30),
    axis.text.y=element_text(angle = 0, colour = "black", size = 80),axis.title.x = element_text(size=120),
    axis.title.y = element_text(size=120),
    legend.position = "none",
    strip.text = element_text(size = 100)) + facet_wrap(~ max_dimension, nrow = 5, scale = "free")

#### 3.partially enlarged (take the first 11 words of morality as example)
tmp4Mor <- tmp4 %>% dplyr::filter(
  max_dimension == "morality"
) %>% dplyr::arrange(
  desc(max_values)
)
tmp3Mor <- as.data.frame(tmp3) %>% dplyr::filter(
  word %in% tmp4Mor$word[c(1:11)]
)
belong_to_name1 <- c('狼心狗肺' = "cruel and unscrupulous 狼心狗肺",
                     '无恶不作' = "commit all manners of crimes 无恶不作",
                     '善良' = "kind-hearted 善良",'伤风败俗'="immorality 伤风败俗",
                     '孝顺'="obedient 孝顺",'黑心'='black-hearted 黑心',
                     '大逆不道'="rebellious 大逆不道",
                     '忘恩负义'="ungrateful 忘恩负义",'丧尽天良'="unscrupulous 丧尽天良",
                     '不孝'="unfilial 不孝",'缺德'="unethical 缺德")

tmp3Mor$word<-factor(
  tmp3Mor$word,
  levels = c("狼心狗肺","无恶不作","善良","伤风败俗","孝顺","黑心",
             "大逆不道", "忘恩负义","丧尽天良","不孝","缺德"),
  labels = belong_to_name1
)

ggplot(data = tmp3Mor, aes(x = word, y = effective_degree, fill = belong_to)) +
  geom_bar(position = "stack", stat = "identity", width = 0.6) +
  scale_fill_manual(
    values=rev(c("#FF00AA","#00FF00","#3333ff", "#FF00FF", "#FFFF00","#0099e6","#ff4d4d")),
    labels=c("Appearance","Socioeconomic status","Sociability","Competence","Morality","Non-five","Ambiguous"),
    name = "Dimension"
  ) +
  labs(x="Words",y="Percentage") +
  theme(
    axis.text.x=element_text(angle = 90, colour = "black", hjust=1,size = 100),
    axis.text.y=element_text(angle = 0, colour = "black", size = 100),axis.title.x = element_text(size=130,margin = margin(t=-500)),
    axis.title.y = element_text(size=130),
    legend.title = element_text(size=130),legend.text = element_text(size=100),
    strip.text = element_text(size = 100),legend.key.width=unit(3,'cm'))+
    facet_wrap(~ max_dimension, nrow = 5, scale = "free")
```

## Words list
```{r Words list}
tmp5 <- process_data %>% dplyr::filter(
  !is.na(validity)
) %>% dplyr::nest_by(
  word
) %>% dplyr::mutate(
  mean_validity = mean(data$validity),sd_validity = sd(data$validity)
) %>% dplyr::select(-data)

tmp6 <- tmp4 %>% dplyr::mutate(
  mean_validity = tmp5$mean_validity[tmp5$word == word],sd_validity = tmp5$sd_validity[tmp5$word == word]
)

tmp6_1<-tmp6 %>% dplyr::filter(max_dimension %in% c("appearance","socioEconomicStatus","socialAbility","ability","morality"))
tmp6_1$max_dimension <- factor(tmp6_1$max_dimension, levels = c("appearance", "socioEconomicStatus","socialAbility","ability", "morality"
))

tmp7 <- process_data %>% dplyr::filter(
  !is.na(rating)) %>% dplyr::nest_by(word, dimensionEn) %>% 
  dplyr::mutate(mean_rating = mean(data$rating),sd_rating = sd(data$rating)
  ) %>% dplyr::select(-data)

# tmp8 is the last generated word list
tmp8 <- tmp6_1 %>% left_join(tmp7, by = c("word" = "word"))
tmp8<-tmp8[,c("word","max_dimension","dimensionEn","mean_rating", "sd_rating", "mean_validity", "sd_validity")]
tmp8<-tmp8 %>% pivot_wider(names_from =dimensionEn,values_from=c(mean_rating,sd_rating))
```

## valence classification——bootstrap
```{r valence classification}
set.seed(525)

df_prepare <- process_data %>%
  dplyr::filter(
    !is.na(validity), 
    isTrap == FALSE
  ) %>%
  dplyr::select(
    subj_idx, Type, word, dimensionEn, validity
  )

bootstrap_function <- function(df_prepare, indices) {
  sample_data <- df_prepare[indices, ]
  mean(sample_data$validity)
}

unique_words <- unique(df_prepare$word)
ci_results <- list()
for (word in unique_words) {
  word_data <- df_prepare[df_prepare$word == word,]
  bootstrap_results <- boot(data = word_data, statistic = bootstrap_function, R = 5000, sim = "ordinary")
  conf_interval <- boot.ci(bootstrap_results, type = "perc")
  ci_results[[word]] <- conf_interval
}

ci_data <- data.frame(word=character(), lower=numeric(), upper=numeric(), stringsAsFactors=FALSE)
for (word in names(ci_results)) {
  ci <- ci_results[[word]]
  lower_bound <- ci$percent[4]  
  upper_bound <- ci$percent[5] 
  ci_data <- rbind(ci_data, data.frame(word=word, lower=lower_bound, upper=upper_bound))
}

write.csv(ci_data, "confidence_intervals.csv", row.names=FALSE)
```

### valence violin chart
corresponds to Fig.6 in the article
```{r violin chart,warning=FALSE}
#words_val_res:containing valence information and confidence intervals for each dimension's words 
words_val_res <- read.csv("./words_val_res.csv",header = T,encoding="UTF-8")
words_val_res$dimension <- as.factor(words_val_res$dimension)
words_val_res$valence <- as.factor(words_val_res$valence)

valence_colors <- c("Positive" = "#ff6666",  
                    "Neutral" = "#ffaf33",   
                    "Negative" = "#6666ff")  


for_list <- c(
  "appearance", "socioEconomicStatus",
  "socialAbility", "competence", "morality"
)

for_x_title <- c(
  "Appearance", "Socioeconomic status",
  "Sociability", "Competence", "Morality"
)

get_color <- function(i) {
  if (i == 1) {
    "black"
  } else {
    "white"
  }
}

plot_data <- list()

for (i in seq_along(for_list)) {
  data_subset <- words_val_res %>%
    filter(dimension == for_list[i]) %>%
    mutate(dimension = for_x_title[i])
  plot_data[[i]] <- data_subset
}
 
combined_data <- do.call(rbind, plot_data)

violin_plot <- ggplot(combined_data, aes(x = dimension, y = (lower + upper) / 2, fill = valence, color = valence)) +
  geom_point(data = combined_data %>% filter(valence == "Neutral"), size = 4) +
  geom_half_violin(data = combined_data %>% filter(valence != "Neutral"), side = "r", position = position_nudge(x = 0, y = 0)) +
  geom_half_point(data = combined_data %>% filter(valence != "Neutral"), side = "l", position = position_nudge(x = 0, y = 0), size = 4, alpha = 1) +
  geom_hline(yintercept = 5, linetype = "dashed", color = "black", size = 1) +
  scale_fill_manual(values = valence_colors) +
  scale_color_manual(values = valence_colors) +
  labs(y = "Average Rating", fill = "Valence") +
  scale_y_continuous(limits = c(1, 9)) +
  scale_x_discrete(limits = for_x_title) +
  theme_bw() +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black",size = 1),
        axis.ticks = element_line(colour = "black", size = 1),
        axis.ticks.length = unit(0.25, "cm"), 
        axis.text.x = element_text(colour = "black", size = 65),
        axis.title.x = element_blank(),
        axis.title.y = element_text(colour = "black", size = 80),
        axis.text.y = element_text(colour = "black", size = 65),
        legend.title = element_text(size = 80),
        legend.text = element_text(size = 65),
        legend.position = "right") + 
  guides(fill = guide_legend(title = "Valence"), color = guide_legend(title = "Valence"))

plot(violin_plot)
```
